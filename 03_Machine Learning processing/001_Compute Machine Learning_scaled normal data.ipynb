{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32b19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b141b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal = pd.read_csv('Save_Normal_data.csv')\n",
    "scaled_data_normal = pd.read_csv('Save_Normal_data_SCALED.csv')\n",
    "scaled_fac = pd.read_csv('Normal_Scaled_Factor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3834f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phaseSelect(value, let):\n",
    "    result = 0\n",
    "    if (let in value):\n",
    "        result = 1\n",
    "    else:\n",
    "        result =0\n",
    "    return result\n",
    "dict_voltage= {\"MediumVoltage_ShortLine\":34641.0161513775\n",
    "               , \"HighVoltage_ShortLine\":326598\n",
    "               , \"HighVoltage_LongLine300\":326598\n",
    "              , \"HighVoltage_LongLine500\":326598}\n",
    "def VoltageSelect(typeLine):\n",
    "    return dict_voltage[typeLine]\n",
    "scaled_data_normal[\"Is_A\"] = scaled_data_normal[\"phase\"].apply(lambda x: phaseSelect(x,\"A\"))\n",
    "scaled_data_normal[\"Is_B\"] = scaled_data_normal[\"phase\"].apply(lambda x: phaseSelect(x,\"B\"))\n",
    "scaled_data_normal[\"Is_C\"] = scaled_data_normal[\"phase\"].apply(lambda x: phaseSelect(x,\"C\"))\n",
    "scaled_type = pd.get_dummies(scaled_data_normal[\"Type\"],drop_first=True)\n",
    "scaled_data_normal = pd.concat([scaled_data_normal,scaled_type],axis=1)\n",
    "data_normal[\"Is_A\"] = data_normal[\"phase\"].apply(lambda x: phaseSelect(x,\"A\"))\n",
    "data_normal[\"Is_B\"] = data_normal[\"phase\"].apply(lambda x: phaseSelect(x,\"B\"))\n",
    "data_normal[\"Is_C\"] = data_normal[\"phase\"].apply(lambda x: phaseSelect(x,\"C\"))\n",
    "normal_type = pd.get_dummies(data_normal[\"Type\"],drop_first=True)\n",
    "data_normal = pd.concat([data_normal, scaled_type],axis=1)\n",
    "#data_normal[\"NewCycle\"] = data_normal[\"cycle\"]/20\n",
    "#scaled_data_normal[\"NewCycle\"] = scaled_data_normal[\"cycle\"]/20\n",
    "\n",
    "data_normal[\"VoltageGenerator\"] = data_normal[\"Type\"].apply(lambda x: VoltageSelect(x))\n",
    "scaled_data_normal[\"VoltageGenerator\"] = scaled_data_normal[\"Type\"].apply(lambda x: VoltageSelect(x))/max(dict_voltage.values())\n",
    "scaled_data_normal[\"ScaledLength\"] = scaled_data_normal[\"TotalLength\"]/scaled_data_normal[\"TotalLength\"].max()\n",
    "data_normal[\"ScaledLength\"] = data_normal[\"TotalLength\"]/data_normal[\"TotalLength\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f784a290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62c0ebcd",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0267ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_column = list(scaled_data_normal.columns)\n",
    "studied_columns_all = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','ScaledLength',\n",
    "'Iabc_generator_ContinueComponent_PhaseA','Iabc_generator_ContinueComponent_PhaseB','Iabc_generator_ContinueComponent_PhaseC','Iabc_generator_EffectiveComponent_PhaseA','Iabc_generator_EffectiveComponent_PhaseB','Iabc_generator_EffectiveComponent_PhaseC','Iabc_generator_FirstArmonic_PhaseA_Value','Iabc_generator_FirstArmonic_PhaseA_Angle','Iabc_generator_FirstArmonic_PhaseB_Value','Iabc_generator_FirstArmonic_PhaseB_Angle','Iabc_generator_FirstArmonic_PhaseC_Value','Iabc_generator_FirstArmonic_PhaseC_Angle','Iabc_generator_DeformingComponent_PhaseA','Iabc_generator_DeformingComponent_PhaseB','Iabc_generator_DeformingComponent_PhaseC','Iabc_generator_CoefficientDistorsion_PhaseA','Iabc_generator_CoefficientDistorsion_PhaseB','Iabc_generator_CoefficientDistorsion_PhaseC','Iabc_generator_CoefficientDistorsionContinue_PhaseA','Iabc_generator_CoefficientDistorsionContinue_PhaseB','Iabc_generator_CoefficientDistorsionContinue_PhaseC','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseA','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseB','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseC','Iabc_generator_DirectComponent_Value','Iabc_generator_DirectComponent_Angle','Iabc_generator_InverseComponent_Value','Iabc_generator_InverseComponent_Angle','Iabc_generator_ZeroComponent_Value','Iabc_generator_ZeroComponent_Angle','Iabc_generator_CoefficeintNegativeAsimetry','Iabc_generator_CoefficeintZeroAsimetry',\n",
    "'Vabc_generator_ContinueComponent_PhaseA','Vabc_generator_ContinueComponent_PhaseB','Vabc_generator_ContinueComponent_PhaseC','Vabc_generator_EffectiveComponent_PhaseA','Vabc_generator_EffectiveComponent_PhaseB','Vabc_generator_EffectiveComponent_PhaseC','Vabc_generator_FirstArmonic_PhaseA_Value','Vabc_generator_FirstArmonic_PhaseA_Angle','Vabc_generator_FirstArmonic_PhaseB_Value','Vabc_generator_FirstArmonic_PhaseB_Angle','Vabc_generator_FirstArmonic_PhaseC_Value','Vabc_generator_FirstArmonic_PhaseC_Angle','Vabc_generator_DeformingComponent_PhaseA','Vabc_generator_DeformingComponent_PhaseB','Vabc_generator_DeformingComponent_PhaseC','Vabc_generator_CoefficientDistorsion_PhaseA','Vabc_generator_CoefficientDistorsion_PhaseB','Vabc_generator_CoefficientDistorsion_PhaseC','Vabc_generator_CoefficientDistorsionContinue_PhaseA','Vabc_generator_CoefficientDistorsionContinue_PhaseB','Vabc_generator_CoefficientDistorsionContinue_PhaseC','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseA','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseB','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseC','Vabc_generator_DirectComponent_Value','Vabc_generator_DirectComponent_Angle','Vabc_generator_InverseComponent_Value','Vabc_generator_InverseComponent_Angle','Vabc_generator_ZeroComponent_Value','Vabc_generator_ZeroComponent_Angle','Vabc_generator_CoefficeintNegativeAsimetry','Vabc_generator_CoefficeintZeroAsimetry',\n",
    "'Iabc_consumator_ContinueComponent_PhaseA','Iabc_consumator_ContinueComponent_PhaseB','Iabc_consumator_ContinueComponent_PhaseC','Iabc_consumator_EffectiveComponent_PhaseA','Iabc_consumator_EffectiveComponent_PhaseB','Iabc_consumator_EffectiveComponent_PhaseC','Iabc_consumator_FirstArmonic_PhaseA_Value','Iabc_consumator_FirstArmonic_PhaseA_Angle','Iabc_consumator_FirstArmonic_PhaseB_Value','Iabc_consumator_FirstArmonic_PhaseB_Angle','Iabc_consumator_FirstArmonic_PhaseC_Value','Iabc_consumator_FirstArmonic_PhaseC_Angle','Iabc_consumator_DeformingComponent_PhaseA','Iabc_consumator_DeformingComponent_PhaseB','Iabc_consumator_DeformingComponent_PhaseC','Iabc_consumator_CoefficientDistorsion_PhaseA','Iabc_consumator_CoefficientDistorsion_PhaseB','Iabc_consumator_CoefficientDistorsion_PhaseC','Iabc_consumator_CoefficientDistorsionContinue_PhaseA','Iabc_consumator_CoefficientDistorsionContinue_PhaseB','Iabc_consumator_CoefficientDistorsionContinue_PhaseC','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseA','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseB','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseC','Iabc_consumator_DirectComponent_Value','Iabc_consumator_DirectComponent_Angle','Iabc_consumator_InverseComponent_Value','Iabc_consumator_InverseComponent_Angle','Iabc_consumator_ZeroComponent_Value','Iabc_consumator_ZeroComponent_Angle','Iabc_consumator_CoefficeintNegativeAsimetry','Iabc_consumator_CoefficeintZeroAsimetry',\n",
    "'Vabc_consumator_ContinueComponent_PhaseA','Vabc_consumator_ContinueComponent_PhaseB','Vabc_consumator_ContinueComponent_PhaseC','Vabc_consumator_EffectiveComponent_PhaseA','Vabc_consumator_EffectiveComponent_PhaseB','Vabc_consumator_EffectiveComponent_PhaseC','Vabc_consumator_FirstArmonic_PhaseA_Value','Vabc_consumator_FirstArmonic_PhaseA_Angle','Vabc_consumator_FirstArmonic_PhaseB_Value','Vabc_consumator_FirstArmonic_PhaseB_Angle','Vabc_consumator_FirstArmonic_PhaseC_Value','Vabc_consumator_FirstArmonic_PhaseC_Angle','Vabc_consumator_DeformingComponent_PhaseA','Vabc_consumator_DeformingComponent_PhaseB','Vabc_consumator_DeformingComponent_PhaseC','Vabc_consumator_CoefficientDistorsion_PhaseA','Vabc_consumator_CoefficientDistorsion_PhaseB','Vabc_consumator_CoefficientDistorsion_PhaseC','Vabc_consumator_CoefficientDistorsionContinue_PhaseA','Vabc_consumator_CoefficientDistorsionContinue_PhaseB','Vabc_consumator_CoefficientDistorsionContinue_PhaseC','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseA','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseB','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseC','Vabc_consumator_DirectComponent_Value','Vabc_consumator_DirectComponent_Angle','Vabc_consumator_InverseComponent_Value','Vabc_consumator_InverseComponent_Angle','Vabc_consumator_ZeroComponent_Value','Vabc_consumator_ZeroComponent_Angle','Vabc_consumator_CoefficeintNegativeAsimetry','Vabc_consumator_CoefficeintZeroAsimetry'\n",
    "]\n",
    "\n",
    "studied_columns_generator = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','ScaledLength',\n",
    "'Iabc_generator_ContinueComponent_PhaseA','Iabc_generator_ContinueComponent_PhaseB','Iabc_generator_ContinueComponent_PhaseC','Iabc_generator_EffectiveComponent_PhaseA','Iabc_generator_EffectiveComponent_PhaseB','Iabc_generator_EffectiveComponent_PhaseC','Iabc_generator_FirstArmonic_PhaseA_Value','Iabc_generator_FirstArmonic_PhaseA_Angle','Iabc_generator_FirstArmonic_PhaseB_Value','Iabc_generator_FirstArmonic_PhaseB_Angle','Iabc_generator_FirstArmonic_PhaseC_Value','Iabc_generator_FirstArmonic_PhaseC_Angle','Iabc_generator_DeformingComponent_PhaseA','Iabc_generator_DeformingComponent_PhaseB','Iabc_generator_DeformingComponent_PhaseC','Iabc_generator_CoefficientDistorsion_PhaseA','Iabc_generator_CoefficientDistorsion_PhaseB','Iabc_generator_CoefficientDistorsion_PhaseC','Iabc_generator_CoefficientDistorsionContinue_PhaseA','Iabc_generator_CoefficientDistorsionContinue_PhaseB','Iabc_generator_CoefficientDistorsionContinue_PhaseC','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseA','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseB','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseC','Iabc_generator_DirectComponent_Value','Iabc_generator_DirectComponent_Angle','Iabc_generator_InverseComponent_Value','Iabc_generator_InverseComponent_Angle','Iabc_generator_ZeroComponent_Value','Iabc_generator_ZeroComponent_Angle','Iabc_generator_CoefficeintNegativeAsimetry','Iabc_generator_CoefficeintZeroAsimetry',\n",
    "'Vabc_generator_ContinueComponent_PhaseA','Vabc_generator_ContinueComponent_PhaseB','Vabc_generator_ContinueComponent_PhaseC','Vabc_generator_EffectiveComponent_PhaseA','Vabc_generator_EffectiveComponent_PhaseB','Vabc_generator_EffectiveComponent_PhaseC','Vabc_generator_FirstArmonic_PhaseA_Value','Vabc_generator_FirstArmonic_PhaseA_Angle','Vabc_generator_FirstArmonic_PhaseB_Value','Vabc_generator_FirstArmonic_PhaseB_Angle','Vabc_generator_FirstArmonic_PhaseC_Value','Vabc_generator_FirstArmonic_PhaseC_Angle','Vabc_generator_DeformingComponent_PhaseA','Vabc_generator_DeformingComponent_PhaseB','Vabc_generator_DeformingComponent_PhaseC','Vabc_generator_CoefficientDistorsion_PhaseA','Vabc_generator_CoefficientDistorsion_PhaseB','Vabc_generator_CoefficientDistorsion_PhaseC','Vabc_generator_CoefficientDistorsionContinue_PhaseA','Vabc_generator_CoefficientDistorsionContinue_PhaseB','Vabc_generator_CoefficientDistorsionContinue_PhaseC','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseA','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseB','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseC','Vabc_generator_DirectComponent_Value','Vabc_generator_DirectComponent_Angle','Vabc_generator_InverseComponent_Value','Vabc_generator_InverseComponent_Angle','Vabc_generator_ZeroComponent_Value','Vabc_generator_ZeroComponent_Angle','Vabc_generator_CoefficeintNegativeAsimetry','Vabc_generator_CoefficeintZeroAsimetry'\n",
    "]\n",
    "\n",
    "studied_columns_consumator = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','ScaledLength',\n",
    "'Iabc_consumator_ContinueComponent_PhaseA','Iabc_consumator_ContinueComponent_PhaseB','Iabc_consumator_ContinueComponent_PhaseC','Iabc_consumator_EffectiveComponent_PhaseA','Iabc_consumator_EffectiveComponent_PhaseB','Iabc_consumator_EffectiveComponent_PhaseC','Iabc_consumator_FirstArmonic_PhaseA_Value','Iabc_consumator_FirstArmonic_PhaseA_Angle','Iabc_consumator_FirstArmonic_PhaseB_Value','Iabc_consumator_FirstArmonic_PhaseB_Angle','Iabc_consumator_FirstArmonic_PhaseC_Value','Iabc_consumator_FirstArmonic_PhaseC_Angle','Iabc_consumator_DeformingComponent_PhaseA','Iabc_consumator_DeformingComponent_PhaseB','Iabc_consumator_DeformingComponent_PhaseC','Iabc_consumator_CoefficientDistorsion_PhaseA','Iabc_consumator_CoefficientDistorsion_PhaseB','Iabc_consumator_CoefficientDistorsion_PhaseC','Iabc_consumator_CoefficientDistorsionContinue_PhaseA','Iabc_consumator_CoefficientDistorsionContinue_PhaseB','Iabc_consumator_CoefficientDistorsionContinue_PhaseC','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseA','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseB','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseC','Iabc_consumator_DirectComponent_Value','Iabc_consumator_DirectComponent_Angle','Iabc_consumator_InverseComponent_Value','Iabc_consumator_InverseComponent_Angle','Iabc_consumator_ZeroComponent_Value','Iabc_consumator_ZeroComponent_Angle','Iabc_consumator_CoefficeintNegativeAsimetry','Iabc_consumator_CoefficeintZeroAsimetry',\n",
    "'Vabc_consumator_ContinueComponent_PhaseA','Vabc_consumator_ContinueComponent_PhaseB','Vabc_consumator_ContinueComponent_PhaseC','Vabc_consumator_EffectiveComponent_PhaseA','Vabc_consumator_EffectiveComponent_PhaseB','Vabc_consumator_EffectiveComponent_PhaseC','Vabc_consumator_FirstArmonic_PhaseA_Value','Vabc_consumator_FirstArmonic_PhaseA_Angle','Vabc_consumator_FirstArmonic_PhaseB_Value','Vabc_consumator_FirstArmonic_PhaseB_Angle','Vabc_consumator_FirstArmonic_PhaseC_Value','Vabc_consumator_FirstArmonic_PhaseC_Angle','Vabc_consumator_DeformingComponent_PhaseA','Vabc_consumator_DeformingComponent_PhaseB','Vabc_consumator_DeformingComponent_PhaseC','Vabc_consumator_CoefficientDistorsion_PhaseA','Vabc_consumator_CoefficientDistorsion_PhaseB','Vabc_consumator_CoefficientDistorsion_PhaseC','Vabc_consumator_CoefficientDistorsionContinue_PhaseA','Vabc_consumator_CoefficientDistorsionContinue_PhaseB','Vabc_consumator_CoefficientDistorsionContinue_PhaseC','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseA','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseB','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseC','Vabc_consumator_DirectComponent_Value','Vabc_consumator_DirectComponent_Angle','Vabc_consumator_InverseComponent_Value','Vabc_consumator_InverseComponent_Angle','Vabc_consumator_ZeroComponent_Value','Vabc_consumator_ZeroComponent_Angle','Vabc_consumator_CoefficeintNegativeAsimetry','Vabc_consumator_CoefficeintZeroAsimetry'\n",
    "]\n",
    "all_column_normal = list(data_normal.columns)\n",
    "studied_columns_all_normal = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','TotalLength',\n",
    "'Iabc_generator_ContinueComponent_PhaseA','Iabc_generator_ContinueComponent_PhaseB','Iabc_generator_ContinueComponent_PhaseC','Iabc_generator_EffectiveComponent_PhaseA','Iabc_generator_EffectiveComponent_PhaseB','Iabc_generator_EffectiveComponent_PhaseC','Iabc_generator_FirstArmonic_PhaseA_Value','Iabc_generator_FirstArmonic_PhaseA_Angle','Iabc_generator_FirstArmonic_PhaseB_Value','Iabc_generator_FirstArmonic_PhaseB_Angle','Iabc_generator_FirstArmonic_PhaseC_Value','Iabc_generator_FirstArmonic_PhaseC_Angle','Iabc_generator_DeformingComponent_PhaseA','Iabc_generator_DeformingComponent_PhaseB','Iabc_generator_DeformingComponent_PhaseC','Iabc_generator_CoefficientDistorsion_PhaseA','Iabc_generator_CoefficientDistorsion_PhaseB','Iabc_generator_CoefficientDistorsion_PhaseC','Iabc_generator_CoefficientDistorsionContinue_PhaseA','Iabc_generator_CoefficientDistorsionContinue_PhaseB','Iabc_generator_CoefficientDistorsionContinue_PhaseC','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseA','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseB','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseC','Iabc_generator_DirectComponent_Value','Iabc_generator_DirectComponent_Angle','Iabc_generator_InverseComponent_Value','Iabc_generator_InverseComponent_Angle','Iabc_generator_ZeroComponent_Value','Iabc_generator_ZeroComponent_Angle','Iabc_generator_CoefficeintNegativeAsimetry','Iabc_generator_CoefficeintZeroAsimetry',\n",
    "'Vabc_generator_ContinueComponent_PhaseA','Vabc_generator_ContinueComponent_PhaseB','Vabc_generator_ContinueComponent_PhaseC','Vabc_generator_EffectiveComponent_PhaseA','Vabc_generator_EffectiveComponent_PhaseB','Vabc_generator_EffectiveComponent_PhaseC','Vabc_generator_FirstArmonic_PhaseA_Value','Vabc_generator_FirstArmonic_PhaseA_Angle','Vabc_generator_FirstArmonic_PhaseB_Value','Vabc_generator_FirstArmonic_PhaseB_Angle','Vabc_generator_FirstArmonic_PhaseC_Value','Vabc_generator_FirstArmonic_PhaseC_Angle','Vabc_generator_DeformingComponent_PhaseA','Vabc_generator_DeformingComponent_PhaseB','Vabc_generator_DeformingComponent_PhaseC','Vabc_generator_CoefficientDistorsion_PhaseA','Vabc_generator_CoefficientDistorsion_PhaseB','Vabc_generator_CoefficientDistorsion_PhaseC','Vabc_generator_CoefficientDistorsionContinue_PhaseA','Vabc_generator_CoefficientDistorsionContinue_PhaseB','Vabc_generator_CoefficientDistorsionContinue_PhaseC','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseA','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseB','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseC','Vabc_generator_DirectComponent_Value','Vabc_generator_DirectComponent_Angle','Vabc_generator_InverseComponent_Value','Vabc_generator_InverseComponent_Angle','Vabc_generator_ZeroComponent_Value','Vabc_generator_ZeroComponent_Angle','Vabc_generator_CoefficeintNegativeAsimetry','Vabc_generator_CoefficeintZeroAsimetry',\n",
    "'Iabc_consumator_ContinueComponent_PhaseA','Iabc_consumator_ContinueComponent_PhaseB','Iabc_consumator_ContinueComponent_PhaseC','Iabc_consumator_EffectiveComponent_PhaseA','Iabc_consumator_EffectiveComponent_PhaseB','Iabc_consumator_EffectiveComponent_PhaseC','Iabc_consumator_FirstArmonic_PhaseA_Value','Iabc_consumator_FirstArmonic_PhaseA_Angle','Iabc_consumator_FirstArmonic_PhaseB_Value','Iabc_consumator_FirstArmonic_PhaseB_Angle','Iabc_consumator_FirstArmonic_PhaseC_Value','Iabc_consumator_FirstArmonic_PhaseC_Angle','Iabc_consumator_DeformingComponent_PhaseA','Iabc_consumator_DeformingComponent_PhaseB','Iabc_consumator_DeformingComponent_PhaseC','Iabc_consumator_CoefficientDistorsion_PhaseA','Iabc_consumator_CoefficientDistorsion_PhaseB','Iabc_consumator_CoefficientDistorsion_PhaseC','Iabc_consumator_CoefficientDistorsionContinue_PhaseA','Iabc_consumator_CoefficientDistorsionContinue_PhaseB','Iabc_consumator_CoefficientDistorsionContinue_PhaseC','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseA','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseB','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseC','Iabc_consumator_DirectComponent_Value','Iabc_consumator_DirectComponent_Angle','Iabc_consumator_InverseComponent_Value','Iabc_consumator_InverseComponent_Angle','Iabc_consumator_ZeroComponent_Value','Iabc_consumator_ZeroComponent_Angle','Iabc_consumator_CoefficeintNegativeAsimetry','Iabc_consumator_CoefficeintZeroAsimetry',\n",
    "'Vabc_consumator_ContinueComponent_PhaseA','Vabc_consumator_ContinueComponent_PhaseB','Vabc_consumator_ContinueComponent_PhaseC','Vabc_consumator_EffectiveComponent_PhaseA','Vabc_consumator_EffectiveComponent_PhaseB','Vabc_consumator_EffectiveComponent_PhaseC','Vabc_consumator_FirstArmonic_PhaseA_Value','Vabc_consumator_FirstArmonic_PhaseA_Angle','Vabc_consumator_FirstArmonic_PhaseB_Value','Vabc_consumator_FirstArmonic_PhaseB_Angle','Vabc_consumator_FirstArmonic_PhaseC_Value','Vabc_consumator_FirstArmonic_PhaseC_Angle','Vabc_consumator_DeformingComponent_PhaseA','Vabc_consumator_DeformingComponent_PhaseB','Vabc_consumator_DeformingComponent_PhaseC','Vabc_consumator_CoefficientDistorsion_PhaseA','Vabc_consumator_CoefficientDistorsion_PhaseB','Vabc_consumator_CoefficientDistorsion_PhaseC','Vabc_consumator_CoefficientDistorsionContinue_PhaseA','Vabc_consumator_CoefficientDistorsionContinue_PhaseB','Vabc_consumator_CoefficientDistorsionContinue_PhaseC','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseA','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseB','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseC','Vabc_consumator_DirectComponent_Value','Vabc_consumator_DirectComponent_Angle','Vabc_consumator_InverseComponent_Value','Vabc_consumator_InverseComponent_Angle','Vabc_consumator_ZeroComponent_Value','Vabc_consumator_ZeroComponent_Angle','Vabc_consumator_CoefficeintNegativeAsimetry','Vabc_consumator_CoefficeintZeroAsimetry'\n",
    "]\n",
    "\n",
    "studied_columns_generator_normal = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','TotalLength',\n",
    "'Iabc_generator_ContinueComponent_PhaseA','Iabc_generator_ContinueComponent_PhaseB','Iabc_generator_ContinueComponent_PhaseC','Iabc_generator_EffectiveComponent_PhaseA','Iabc_generator_EffectiveComponent_PhaseB','Iabc_generator_EffectiveComponent_PhaseC','Iabc_generator_FirstArmonic_PhaseA_Value','Iabc_generator_FirstArmonic_PhaseA_Angle','Iabc_generator_FirstArmonic_PhaseB_Value','Iabc_generator_FirstArmonic_PhaseB_Angle','Iabc_generator_FirstArmonic_PhaseC_Value','Iabc_generator_FirstArmonic_PhaseC_Angle','Iabc_generator_DeformingComponent_PhaseA','Iabc_generator_DeformingComponent_PhaseB','Iabc_generator_DeformingComponent_PhaseC','Iabc_generator_CoefficientDistorsion_PhaseA','Iabc_generator_CoefficientDistorsion_PhaseB','Iabc_generator_CoefficientDistorsion_PhaseC','Iabc_generator_CoefficientDistorsionContinue_PhaseA','Iabc_generator_CoefficientDistorsionContinue_PhaseB','Iabc_generator_CoefficientDistorsionContinue_PhaseC','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseA','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseB','Iabc_generator_CoefficientDistorsionFirstArmonic_PhaseC','Iabc_generator_DirectComponent_Value','Iabc_generator_DirectComponent_Angle','Iabc_generator_InverseComponent_Value','Iabc_generator_InverseComponent_Angle','Iabc_generator_ZeroComponent_Value','Iabc_generator_ZeroComponent_Angle','Iabc_generator_CoefficeintNegativeAsimetry','Iabc_generator_CoefficeintZeroAsimetry',\n",
    "'Vabc_generator_ContinueComponent_PhaseA','Vabc_generator_ContinueComponent_PhaseB','Vabc_generator_ContinueComponent_PhaseC','Vabc_generator_EffectiveComponent_PhaseA','Vabc_generator_EffectiveComponent_PhaseB','Vabc_generator_EffectiveComponent_PhaseC','Vabc_generator_FirstArmonic_PhaseA_Value','Vabc_generator_FirstArmonic_PhaseA_Angle','Vabc_generator_FirstArmonic_PhaseB_Value','Vabc_generator_FirstArmonic_PhaseB_Angle','Vabc_generator_FirstArmonic_PhaseC_Value','Vabc_generator_FirstArmonic_PhaseC_Angle','Vabc_generator_DeformingComponent_PhaseA','Vabc_generator_DeformingComponent_PhaseB','Vabc_generator_DeformingComponent_PhaseC','Vabc_generator_CoefficientDistorsion_PhaseA','Vabc_generator_CoefficientDistorsion_PhaseB','Vabc_generator_CoefficientDistorsion_PhaseC','Vabc_generator_CoefficientDistorsionContinue_PhaseA','Vabc_generator_CoefficientDistorsionContinue_PhaseB','Vabc_generator_CoefficientDistorsionContinue_PhaseC','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseA','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseB','Vabc_generator_CoefficientDistorsionFirstArmonic_PhaseC','Vabc_generator_DirectComponent_Value','Vabc_generator_DirectComponent_Angle','Vabc_generator_InverseComponent_Value','Vabc_generator_InverseComponent_Angle','Vabc_generator_ZeroComponent_Value','Vabc_generator_ZeroComponent_Angle','Vabc_generator_CoefficeintNegativeAsimetry','Vabc_generator_CoefficeintZeroAsimetry'\n",
    "]\n",
    "\n",
    "studied_columns_consumator_normal = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','TotalLength',\n",
    "'Iabc_consumator_ContinueComponent_PhaseA','Iabc_consumator_ContinueComponent_PhaseB','Iabc_consumator_ContinueComponent_PhaseC','Iabc_consumator_EffectiveComponent_PhaseA','Iabc_consumator_EffectiveComponent_PhaseB','Iabc_consumator_EffectiveComponent_PhaseC','Iabc_consumator_FirstArmonic_PhaseA_Value','Iabc_consumator_FirstArmonic_PhaseA_Angle','Iabc_consumator_FirstArmonic_PhaseB_Value','Iabc_consumator_FirstArmonic_PhaseB_Angle','Iabc_consumator_FirstArmonic_PhaseC_Value','Iabc_consumator_FirstArmonic_PhaseC_Angle','Iabc_consumator_DeformingComponent_PhaseA','Iabc_consumator_DeformingComponent_PhaseB','Iabc_consumator_DeformingComponent_PhaseC','Iabc_consumator_CoefficientDistorsion_PhaseA','Iabc_consumator_CoefficientDistorsion_PhaseB','Iabc_consumator_CoefficientDistorsion_PhaseC','Iabc_consumator_CoefficientDistorsionContinue_PhaseA','Iabc_consumator_CoefficientDistorsionContinue_PhaseB','Iabc_consumator_CoefficientDistorsionContinue_PhaseC','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseA','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseB','Iabc_consumator_CoefficientDistorsionFirstArmonic_PhaseC','Iabc_consumator_DirectComponent_Value','Iabc_consumator_DirectComponent_Angle','Iabc_consumator_InverseComponent_Value','Iabc_consumator_InverseComponent_Angle','Iabc_consumator_ZeroComponent_Value','Iabc_consumator_ZeroComponent_Angle','Iabc_consumator_CoefficeintNegativeAsimetry','Iabc_consumator_CoefficeintZeroAsimetry',\n",
    "'Vabc_consumator_ContinueComponent_PhaseA','Vabc_consumator_ContinueComponent_PhaseB','Vabc_consumator_ContinueComponent_PhaseC','Vabc_consumator_EffectiveComponent_PhaseA','Vabc_consumator_EffectiveComponent_PhaseB','Vabc_consumator_EffectiveComponent_PhaseC','Vabc_consumator_FirstArmonic_PhaseA_Value','Vabc_consumator_FirstArmonic_PhaseA_Angle','Vabc_consumator_FirstArmonic_PhaseB_Value','Vabc_consumator_FirstArmonic_PhaseB_Angle','Vabc_consumator_FirstArmonic_PhaseC_Value','Vabc_consumator_FirstArmonic_PhaseC_Angle','Vabc_consumator_DeformingComponent_PhaseA','Vabc_consumator_DeformingComponent_PhaseB','Vabc_consumator_DeformingComponent_PhaseC','Vabc_consumator_CoefficientDistorsion_PhaseA','Vabc_consumator_CoefficientDistorsion_PhaseB','Vabc_consumator_CoefficientDistorsion_PhaseC','Vabc_consumator_CoefficientDistorsionContinue_PhaseA','Vabc_consumator_CoefficientDistorsionContinue_PhaseB','Vabc_consumator_CoefficientDistorsionContinue_PhaseC','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseA','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseB','Vabc_consumator_CoefficientDistorsionFirstArmonic_PhaseC','Vabc_consumator_DirectComponent_Value','Vabc_consumator_DirectComponent_Angle','Vabc_consumator_InverseComponent_Value','Vabc_consumator_InverseComponent_Angle','Vabc_consumator_ZeroComponent_Value','Vabc_consumator_ZeroComponent_Angle','Vabc_consumator_CoefficeintNegativeAsimetry','Vabc_consumator_CoefficeintZeroAsimetry'\n",
    "]\n",
    "studied_columns = studied_columns_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de13492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstArmonic_columns_all_normal = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','TotalLength',\n",
    "'Iabc_generator_FirstArmonic_PhaseA_Value','Iabc_generator_FirstArmonic_PhaseA_Angle','Iabc_generator_FirstArmonic_PhaseB_Value','Iabc_generator_FirstArmonic_PhaseB_Angle','Iabc_generator_FirstArmonic_PhaseC_Value','Iabc_generator_FirstArmonic_PhaseC_Angle',\n",
    "'Vabc_generator_FirstArmonic_PhaseA_Value','Vabc_generator_FirstArmonic_PhaseA_Angle','Vabc_generator_FirstArmonic_PhaseB_Value','Vabc_generator_FirstArmonic_PhaseB_Angle','Vabc_generator_FirstArmonic_PhaseC_Value','Vabc_generator_FirstArmonic_PhaseC_Angle',\n",
    "'Iabc_consumator_FirstArmonic_PhaseA_Value','Iabc_consumator_FirstArmonic_PhaseA_Angle','Iabc_consumator_FirstArmonic_PhaseB_Value','Iabc_consumator_FirstArmonic_PhaseB_Angle','Iabc_consumator_FirstArmonic_PhaseC_Value','Iabc_consumator_FirstArmonic_PhaseC_Angle',\n",
    "'Vabc_consumator_FirstArmonic_PhaseA_Value','Vabc_consumator_FirstArmonic_PhaseA_Angle','Vabc_consumator_FirstArmonic_PhaseB_Value','Vabc_consumator_FirstArmonic_PhaseB_Angle','Vabc_consumator_FirstArmonic_PhaseC_Value','Vabc_consumator_FirstArmonic_PhaseC_Angle'\n",
    "]\n",
    "firstArmonic_columns_all = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','ScaledLength',\n",
    "'Iabc_generator_FirstArmonic_PhaseA_Value','Iabc_generator_FirstArmonic_PhaseA_Angle','Iabc_generator_FirstArmonic_PhaseB_Value','Iabc_generator_FirstArmonic_PhaseB_Angle','Iabc_generator_FirstArmonic_PhaseC_Value','Iabc_generator_FirstArmonic_PhaseC_Angle',\n",
    "'Vabc_generator_FirstArmonic_PhaseA_Value','Vabc_generator_FirstArmonic_PhaseA_Angle','Vabc_generator_FirstArmonic_PhaseB_Value','Vabc_generator_FirstArmonic_PhaseB_Angle','Vabc_generator_FirstArmonic_PhaseC_Value','Vabc_generator_FirstArmonic_PhaseC_Angle',\n",
    "'Iabc_consumator_FirstArmonic_PhaseA_Value','Iabc_consumator_FirstArmonic_PhaseA_Angle','Iabc_consumator_FirstArmonic_PhaseB_Value','Iabc_consumator_FirstArmonic_PhaseB_Angle','Iabc_consumator_FirstArmonic_PhaseC_Value','Iabc_consumator_FirstArmonic_PhaseC_Angle',\n",
    "'Vabc_consumator_FirstArmonic_PhaseA_Value','Vabc_consumator_FirstArmonic_PhaseA_Angle','Vabc_consumator_FirstArmonic_PhaseB_Value','Vabc_consumator_FirstArmonic_PhaseB_Angle','Vabc_consumator_FirstArmonic_PhaseC_Value','Vabc_consumator_FirstArmonic_PhaseC_Angle'\n",
    "]\n",
    "firstArmonic_columns_generator_normal = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','TotalLength',\n",
    "'Iabc_generator_FirstArmonic_PhaseA_Value','Iabc_generator_FirstArmonic_PhaseA_Angle','Iabc_generator_FirstArmonic_PhaseB_Value','Iabc_generator_FirstArmonic_PhaseB_Angle','Iabc_generator_FirstArmonic_PhaseC_Value','Iabc_generator_FirstArmonic_PhaseC_Angle',\n",
    "'Vabc_generator_FirstArmonic_PhaseA_Value','Vabc_generator_FirstArmonic_PhaseA_Angle','Vabc_generator_FirstArmonic_PhaseB_Value','Vabc_generator_FirstArmonic_PhaseB_Angle','Vabc_generator_FirstArmonic_PhaseC_Value','Vabc_generator_FirstArmonic_PhaseC_Angle'\n",
    "]\n",
    "firstArmonic_columns_generator = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','ScaledLength',\n",
    "'Iabc_generator_FirstArmonic_PhaseA_Value','Iabc_generator_FirstArmonic_PhaseA_Angle','Iabc_generator_FirstArmonic_PhaseB_Value','Iabc_generator_FirstArmonic_PhaseB_Angle','Iabc_generator_FirstArmonic_PhaseC_Value','Iabc_generator_FirstArmonic_PhaseC_Angle',\n",
    "'Vabc_generator_FirstArmonic_PhaseA_Value','Vabc_generator_FirstArmonic_PhaseA_Angle','Vabc_generator_FirstArmonic_PhaseB_Value','Vabc_generator_FirstArmonic_PhaseB_Angle','Vabc_generator_FirstArmonic_PhaseC_Value','Vabc_generator_FirstArmonic_PhaseC_Angle'\n",
    "]\n",
    "\n",
    "firstArmonic_columns_consumator_normal = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','TotalLength',\n",
    "'Iabc_consumator_FirstArmonic_PhaseA_Value','Iabc_consumator_FirstArmonic_PhaseA_Angle','Iabc_consumator_FirstArmonic_PhaseB_Value','Iabc_consumator_FirstArmonic_PhaseB_Angle','Iabc_consumator_FirstArmonic_PhaseC_Value','Iabc_consumator_FirstArmonic_PhaseC_Angle',\n",
    "'Vabc_consumator_FirstArmonic_PhaseA_Value','Vabc_consumator_FirstArmonic_PhaseA_Angle','Vabc_consumator_FirstArmonic_PhaseB_Value','Vabc_consumator_FirstArmonic_PhaseB_Angle','Vabc_consumator_FirstArmonic_PhaseC_Value','Vabc_consumator_FirstArmonic_PhaseC_Angle'\n",
    "]\n",
    "firstArmonic_columns_consumator = ['FaultLocation_FromGenerator','Is_A','Is_B','Is_C',\n",
    "'HighVoltage_LongLine500','HighVoltage_ShortLine','MediumVoltage_ShortLine','VoltageGenerator','ScaledLength',\n",
    "'Iabc_consumator_FirstArmonic_PhaseA_Value','Iabc_consumator_FirstArmonic_PhaseA_Angle','Iabc_consumator_FirstArmonic_PhaseB_Value','Iabc_consumator_FirstArmonic_PhaseB_Angle','Iabc_consumator_FirstArmonic_PhaseC_Value','Iabc_consumator_FirstArmonic_PhaseC_Angle',\n",
    "'Vabc_consumator_FirstArmonic_PhaseA_Value','Vabc_consumator_FirstArmonic_PhaseA_Angle','Vabc_consumator_FirstArmonic_PhaseB_Value','Vabc_consumator_FirstArmonic_PhaseB_Angle','Vabc_consumator_FirstArmonic_PhaseC_Value','Vabc_consumator_FirstArmonic_PhaseC_Angle'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6132f099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6d90065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f6bfe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = scaled_data_normal[scaled_data_normal[\"cycle\"]==10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ff261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = _data[list(_data.columns)[1:]]\n",
    "y = _data[list(_data.columns)[0]]\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e803bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b603eef",
   "metadata": {},
   "source": [
    "Informații\n",
    "Regression error matrix\n",
    "Root mean square error\n",
    "RMS=√(1/n ∑_(i=0)^n▒(y_i-(y_med ) ̂)^2 )\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/sgd.html#regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#lasso\n",
    "\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#elastic-net\n",
    "\n",
    "https://scikit-learn.org/stable/modules/linear_model.html#ridge-regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/svm.html#regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/svm.html#regression\n",
    "\n",
    "https://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "https://u-next.com/blogs/machine-learning/popular-regression-algorithms-ml/\n",
    "\n",
    "Linear Regression\n",
    "\n",
    "Ridge Regression\n",
    "\n",
    "Neural Network Regression \n",
    "\n",
    "Lasso Regression \n",
    "\n",
    "Decision Tree Regression \n",
    "\n",
    "Random Forest\n",
    "\n",
    "KNN Model \n",
    "\n",
    "Support Vector Machines (SVM)\n",
    "\n",
    "Gausian Regression\n",
    "\n",
    "Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7418fd7",
   "metadata": {},
   "source": [
    "## LinearRegression MODEL\n",
    "pag 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8a7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9921405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeLinearRegression(data_frame, _cycle, columns = studied_columns, _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(x_train,y_train)\n",
    "    predictions=model.predict(x_test)\n",
    "    coeff_df = pd.DataFrame(model.coef_,x.columns,columns=['Coefficient'])\n",
    "    outputStr = ''\n",
    "    outputStr += '\\n' + 'model.intercept_'+'\\t'+str(model.intercept_)+'\\n'\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(metrics.mean_absolute_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(metrics.mean_squared_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(np.sqrt(metrics.mean_squared_error(y_test,predictions)))+'\\n'\n",
    "    outputStr += '\\n' + 'COEFFICIENT'+'\\n'\n",
    "    for index in coeff_df.index.to_list():\n",
    "        outputStr += str(index)+'\\t'+str(coeff_df.at[index,'Coefficient']) + '\\n'\n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(predictions[i]) + '\\t' + str((list(y_test)[i] - predictions[i])*100/list(y_test)[i]) + '\\n'\n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)\n",
    "\n",
    "def ComputeRidgeRegression(data_frame, _cycle, columns = studied_columns, _alpha=1.0, _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    model = linear_model.Ridge(alpha=_alpha)\n",
    "    model.fit(x_train,y_train)\n",
    "    predictions=model.predict(x_test)\n",
    "    coeff_df = pd.DataFrame(model.coef_,x.columns,columns=['Coefficient'])\n",
    "    outputStr = ''\n",
    "    outputStr += '\\n' + 'model.intercept_'+'\\t'+str(model.intercept_)+'\\n'\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(metrics.mean_absolute_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(metrics.mean_squared_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(np.sqrt(metrics.mean_squared_error(y_test,predictions)))+'\\n'\n",
    "    outputStr += '\\n' + 'COEFFICIENT'+'\\n'\n",
    "    for index in coeff_df.index.to_list():\n",
    "        outputStr += str(index)+'\\t'+str(coeff_df.at[index,'Coefficient']) + '\\n'\n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(predictions[i]) + '\\t' + str((list(y_test)[i] - predictions[i])*100/list(y_test)[i]) + '\\n'\n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)\n",
    "\n",
    "def ComputeRidgeRegressionCV(data_frame, _cycle, columns = studied_columns, _alphas=(0.1, 1.0, 10.0), _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    model = linear_model.RidgeCV(alphas=_alphas)\n",
    "    model.fit(x_train,y_train)\n",
    "    predictions=model.predict(x_test)\n",
    "    coeff_df = pd.DataFrame(model.coef_,x.columns,columns=['Coefficient'])\n",
    "    outputStr = ''\n",
    "    outputStr += '\\n' + 'model.intercept_'+'\\t'+str(model.intercept_)+'\\n'\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(metrics.mean_absolute_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(metrics.mean_squared_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(np.sqrt(metrics.mean_squared_error(y_test,predictions)))+'\\n'\n",
    "    outputStr += '\\n' + 'COEFFICIENT'+'\\n'\n",
    "    for index in coeff_df.index.to_list():\n",
    "        outputStr += str(index)+'\\t'+str(coeff_df.at[index,'Coefficient']) + '\\n'\n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(predictions[i]) + '\\t' + str((list(y_test)[i] - predictions[i])*100/list(y_test)[i]) + '\\n'\n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)\n",
    "\n",
    "def ComputeLassoRegression(data_frame, _cycle, columns = studied_columns, _alpha=1.0, _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    model = linear_model.Lasso(alpha=_alpha)\n",
    "    model.fit(x_train,y_train)\n",
    "    predictions=model.predict(x_test)\n",
    "    coeff_df = pd.DataFrame(model.coef_,x.columns,columns=['Coefficient'])\n",
    "    outputStr = ''\n",
    "    outputStr += '\\n' + 'model.intercept_'+'\\t'+str(model.intercept_)+'\\n'\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(metrics.mean_absolute_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(metrics.mean_squared_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(np.sqrt(metrics.mean_squared_error(y_test,predictions)))+'\\n'\n",
    "    outputStr += '\\n' + 'COEFFICIENT'+'\\n'\n",
    "    for index in coeff_df.index.to_list():\n",
    "        outputStr += str(index)+'\\t'+str(coeff_df.at[index,'Coefficient']) + '\\n'\n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(predictions[i]) + '\\t' + str((list(y_test)[i] - predictions[i])*100/list(y_test)[i]) + '\\n'\n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)\n",
    "\n",
    "def ComputeLassoRegression(data_frame, _cycle, columns = studied_columns, _alpha=1.0, _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    model = linear_model.Lasso(alpha = _alpha)\n",
    "    model.fit(x_train,y_train)\n",
    "    predictions=model.predict(x_test)\n",
    "    coeff_df = pd.DataFrame(model.coef_,x.columns,columns=['Coefficient'])\n",
    "    outputStr = ''\n",
    "    outputStr += '\\n' + 'model.intercept_'+'\\t'+str(model.intercept_)+'\\n'\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(metrics.mean_absolute_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(metrics.mean_squared_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(np.sqrt(metrics.mean_squared_error(y_test,predictions)))+'\\n'\n",
    "    outputStr += '\\n' + 'COEFFICIENT'+'\\n'\n",
    "    for index in coeff_df.index.to_list():\n",
    "        outputStr += str(index)+'\\t'+str(coeff_df.at[index,'Coefficient']) + '\\n'\n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(predictions[i]) + '\\t' + str((list(y_test)[i] - predictions[i])*100/list(y_test)[i]) + '\\n'\n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)\n",
    "    \n",
    "def ComputeElasticNet(data_frame, _cycle, columns = studied_columns, _alpha=1.0, _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    model = linear_model.ElasticNet(alpha=_alpha)\n",
    "    model.fit(x_train,y_train)\n",
    "    predictions=model.predict(x_test)\n",
    "    coeff_df = pd.DataFrame(model.coef_,x.columns,columns=['Coefficient'])\n",
    "    outputStr = ''\n",
    "    outputStr += '\\n' + 'model.intercept_'+'\\t'+str(model.intercept_)+'\\n'\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(metrics.mean_absolute_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(metrics.mean_squared_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(np.sqrt(metrics.mean_squared_error(y_test,predictions)))+'\\n'\n",
    "    outputStr += '\\n' + 'COEFFICIENT'+'\\n'\n",
    "    for index in coeff_df.index.to_list():\n",
    "        outputStr += str(index)+'\\t'+str(coeff_df.at[index,'Coefficient']) + '\\n'\n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(predictions[i]) + '\\t' + str((list(y_test)[i] - predictions[i])*100/list(y_test)[i]) + '\\n'\n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)\n",
    "\n",
    "def ComputeSGDRegressor(data_frame, _cycle, columns = studied_columns, _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    model = linear_model.SGDRegressor()\n",
    "    model.fit(x_train,y_train)\n",
    "    predictions=model.predict(x_test)\n",
    "    coeff_df = pd.DataFrame(model.coef_,x.columns,columns=['Coefficient'])\n",
    "    outputStr = ''\n",
    "    outputStr += '\\n' + 'model.intercept_'+'\\t'+str(model.intercept_)+'\\n'\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(metrics.mean_absolute_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(metrics.mean_squared_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(np.sqrt(metrics.mean_squared_error(y_test,predictions)))+'\\n'\n",
    "    outputStr += '\\n' + 'COEFFICIENT'+'\\n'\n",
    "    for index in coeff_df.index.to_list():\n",
    "        outputStr += str(index)+'\\t'+str(coeff_df.at[index,'Coefficient']) + '\\n'\n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(predictions[i]) + '\\t' + str((list(y_test)[i] - predictions[i])*100/list(y_test)[i]) + '\\n'\n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)\n",
    "\n",
    "def ComputePolynomialFeatures(data_frame, _cycle, columns = studied_columns, _degree = 2, _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    poly = PolynomialFeatures(degree=_degree, include_bias=False)\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_mod = poly.fit_transform(x)\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x_mod,y,test_size=_test_size, random_state = _random_state)\n",
    "    \n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(x_train,y_train)\n",
    "    predictions=model.predict(x_test)\n",
    "    outputStr = ''\n",
    "    outputStr += '\\n' + 'model.intercept_'+'\\t'+str(model.intercept_)+'\\n'\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(metrics.mean_absolute_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(metrics.mean_squared_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(np.sqrt(metrics.mean_squared_error(y_test,predictions)))+'\\n'\n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(predictions[i]) + '\\t' + str((list(y_test)[i] - predictions[i])*100/list(y_test)[i]) + '\\n'\n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)\n",
    "\n",
    "def ComputeSVRFeatures(data_frame, _cycle, columns = studied_columns, _kernel = 'rbf', _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    \n",
    "    model = SVR(kernel=_kernel)\n",
    "    model.fit(x_train,y_train)\n",
    "    predictions=model.predict(x_test)\n",
    "    \n",
    "    outputStr = ''\n",
    "    outputStr += '\\n' + 'model.intercept_'+'\\t'+str(model.intercept_)+'\\n'\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(metrics.mean_absolute_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(metrics.mean_squared_error(y_test,predictions))+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(np.sqrt(metrics.mean_squared_error(y_test,predictions)))+'\\n'\n",
    "        \n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(predictions[i]) + '\\t' + str((list(y_test)[i] - predictions[i])*100/list(y_test)[i]) + '\\n'\n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ddc939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d096aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeMachineLearning_Columns1_Scaled(data_frame, _cycle, columns = studied_columns, _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(40,activation='relu'))\n",
    "    model.add(Dense(10,activation='relu'))\n",
    "    model.add(Dense(4,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "    model.fit(x=x_train,y=y_train, validation_data=(x_test,y_test), batch_size=32, epochs=400, verbose=0)\n",
    "    pred= model.predict(x_test)\n",
    "    meanAbsoluteError1 = mean_absolute_error(y_test,pred)\n",
    "    meanSquareError2 = mean_squared_error(y_test,pred)\n",
    "    meanSquareError3 = mean_squared_error(y_test,pred)**0.5\n",
    "    \n",
    "    outputStr = ''\n",
    "\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(meanAbsoluteError1)+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(meanSquareError2)+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(meanSquareError3)+'\\n'\n",
    "    \n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(list(pred)[i]) + '\\t' + str((list(y_test)[i] - list(pred)[i])*100/list(y_test)[i]) + '\\n'\n",
    "        \n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)\n",
    "\n",
    "def ComputeMachineLearning_Columns2_Scaled(data_frame, _cycle, columns = studied_columns, _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(6,activation='relu'))\n",
    "    model.add(Dense(4,activation='relu'))\n",
    "    model.add(Dense(4,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "    model.fit(x=x_train,y=y_train, validation_data=(x_test,y_test), batch_size=32, epochs=400, verbose=0)\n",
    "    pred= model.predict(x_test)\n",
    "    meanAbsoluteError1 = mean_absolute_error(y_test,pred)\n",
    "    meanSquareError2 = mean_squared_error(y_test,pred)\n",
    "    meanSquareError3 = mean_squared_error(y_test,pred)**0.5\n",
    "    \n",
    "    outputStr = ''\n",
    "\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(meanAbsoluteError1)+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(meanSquareError2)+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(meanSquareError3)+'\\n'\n",
    "\n",
    "    \n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(list(pred)[i]) + '\\t' + str((list(y_test)[i] - list(pred)[i])*100/list(y_test)[i]) + '\\n'\n",
    "        \n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)\n",
    "\n",
    "def ComputeMachineLearning_Columns1_Normal(data_frame, _cycle, columns = studied_columns, _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    scaler=MinMaxScaler()\n",
    "    x_train=scaler.fit_transform(x_train)\n",
    "    x_test=scaler.transform(x_test)\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(40,activation='relu'))\n",
    "    model.add(Dense(10,activation='relu'))\n",
    "    model.add(Dense(4,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "    model.fit(x=x_train,y=y_train, validation_data=(x_test,y_test), batch_size=32, epochs=400, verbose=0)\n",
    "    pred= model.predict(x_test)\n",
    "    meanAbsoluteError1 = mean_absolute_error(y_test,pred)\n",
    "    meanSquareError2 = mean_squared_error(y_test,pred)\n",
    "    meanSquareError3 = mean_squared_error(y_test,pred)**0.5\n",
    "    \n",
    "    outputStr = ''\n",
    "\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(meanAbsoluteError1)+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(meanSquareError2)+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(meanSquareError3)+'\\n'\n",
    "    \n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(list(pred)[i]) + '\\t' + str((list(y_test)[i] - list(pred)[i])*100/list(y_test)[i]) + '\\n'\n",
    "        \n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)\n",
    "\n",
    "def ComputeMachineLearning_Columns2_Normal(data_frame, _cycle, columns = studied_columns, _test_size=0.3, _random_state = 42, outpudir=\"output\", outputFile=\"outputFile\"):\n",
    "    _data = data_frame[data_frame[\"cycle\"] == _cycle][columns]\n",
    "    x = _data[list(_data.columns)[1:]]\n",
    "    y = _data[list(_data.columns)[0]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=_test_size, random_state = _random_state)\n",
    "    scaler=MinMaxScaler()\n",
    "    x_train=scaler.fit_transform(x_train)\n",
    "    x_test=scaler.transform(x_test)    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(6,activation='relu'))\n",
    "    model.add(Dense(4,activation='relu'))\n",
    "    model.add(Dense(4,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "    model.fit(x=x_train,y=y_train, validation_data=(x_test,y_test), batch_size=32, epochs=400, verbose=0)\n",
    "    pred= model.predict(x_test)\n",
    "    meanAbsoluteError1 = mean_absolute_error(y_test,pred)\n",
    "    meanSquareError2 = mean_squared_error(y_test,pred)\n",
    "    meanSquareError3 = mean_squared_error(y_test,pred)**0.5\n",
    "    \n",
    "    outputStr = ''\n",
    "\n",
    "    outputStr += 'metrics.mean_absolute_error(y_test,predictions)'+'\\t'+str(meanAbsoluteError1)+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(meanSquareError2)+'\\n'\n",
    "    outputStr += 'metrics.mean_squared_error(y_test,predictions)'+'\\t'+str(meanSquareError3)+'\\n'\n",
    "    \n",
    "    outputStr += '\\n' + 'i\\tValue\\tPrediction\\tError'+'\\n'\n",
    "    for i in range(len(y_test)):\n",
    "        outputStr += str(i) + '\\t' + str(list(y_test)[i]) + '\\t' + str(list(pred)[i]) + '\\t' + str((list(y_test)[i] - list(pred)[i])*100/list(y_test)[i]) + '\\n'\n",
    "    isExist = os.path.exists(outpudir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outpudir)\n",
    "    dir_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.txt')\n",
    "    model_name = os.path.join(os.path.join(os.getcwd(),outpudir),outputFile+'.pkl')\n",
    "    with open(dir_name,'w') as f:\n",
    "        f.writelines(outputStr)\n",
    "    joblib.dump(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0b055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dfa616",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycleList = list(data_normal[\"cycle\"].unique())[10]\n",
    "_data = scaled_data_normal\n",
    "_columns = studied_columns_all\n",
    "_outpudir = \"studied_columns_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eed341",
   "metadata": {},
   "outputs": [],
   "source": [
    "ComputeMachineLearning_Columns1_Scaled(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d92934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_k = 'linear'\n",
    "cycleList = list(data_normal[\"cycle\"].unique())[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23861e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 999us/step\n"
     ]
    }
   ],
   "source": [
    "cycleList = list(data_normal[\"cycle\"].unique())[10:]\n",
    "_data = scaled_data_normal\n",
    "_columns = studied_columns_all\n",
    "_outpudir = \"studied_columns_all\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns1_Scaled(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)\n",
    "_columns = studied_columns_generator\n",
    "_outpudir = \"studied_columns_generator\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns1_Scaled(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)\n",
    "_columns = studied_columns_consumator\n",
    "_outpudir = \"studied_columns_consumator\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns1_Scaled(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)\n",
    "\n",
    "_columns = firstArmonic_columns_all\n",
    "_outpudir = \"firstArmonic_columns_all\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns2_Scaled(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)\n",
    "_columns = firstArmonic_columns_generator\n",
    "_outpudir = \"firstArmonic_columns_generator\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns2_Scaled(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)\n",
    "_columns = firstArmonic_columns_consumator\n",
    "_outpudir = \"firstArmonic_columns_consumator\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns2_Scaled(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3e1cb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1000us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "_data = data_normal\n",
    "_columns = studied_columns_all_normal\n",
    "_outpudir = \"studied_columns_all\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns1_Normal(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)\n",
    "_columns = studied_columns_generator_normal\n",
    "_outpudir = \"studied_columns_generator\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns1_Normal(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)\n",
    "_columns = studied_columns_consumator_normal\n",
    "_outpudir = \"studied_columns_consumator\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns1_Normal(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)\n",
    "\n",
    "_columns = firstArmonic_columns_all_normal\n",
    "_outpudir = \"firstArmonic_columns_all\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns2_Normal(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)\n",
    "_columns = firstArmonic_columns_generator_normal\n",
    "_outpudir = \"firstArmonic_columns_generator\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns2_Normal(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)\n",
    "_columns = firstArmonic_columns_consumator_normal\n",
    "_outpudir = \"firstArmonic_columns_consumator\"\n",
    "for _cycle in cycleList:\n",
    "    _name = \"Cycle_\"+str(_cycle)\n",
    "    ComputeMachineLearning_Columns2_Normal(_data, _cycle, columns = _columns, _test_size=0.3, _random_state = 42, outpudir=_outpudir, outputFile=_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35aaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cabe71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a2610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f2e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea76fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9cd53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554cdec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d729c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pagina 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf68d5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d01f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
