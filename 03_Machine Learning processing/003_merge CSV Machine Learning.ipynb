{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45acfcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import path\n",
    "import math\n",
    "import cmath\n",
    "import shutil\n",
    "import pywt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db575bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDir = '1_ordin_scaled_data_normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21945e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeL1_CSV_v1(inputdir, outputdir):\n",
    "    isExist = os.path.exists(outputdir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outputdir)\n",
    "    _inputDir = os.path.join(os.getcwd(), inputdir)\n",
    "    _outputDir = os.path.join(os.getcwd(), outputdir)\n",
    "    firstArmonic_columnsAll_coef = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_all_Coefficeints.csv'))\n",
    "    firstArmonic_columnsAll_Met = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_all_Metrics.csv'))\n",
    "    firstArmonic_columnsAll_Pre = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_all_Prediction.csv'))\n",
    "    \n",
    "    firstArmonic_columnsGen_coef = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_generator_Coefficeints.csv'))\n",
    "    firstArmonic_columnsGen_Met = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_generator_Metrics.csv'))\n",
    "    firstArmonic_columnsGen_Pre = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_generator_Prediction.csv'))    \n",
    "    \n",
    "    firstArmonic_columnsCons_coef = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_consumator_Coefficeints.csv'))\n",
    "    firstArmonic_columnsCons_Met = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_consumator_Metrics.csv'))\n",
    "    firstArmonic_columnsCons_Pre = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_consumator_Prediction.csv'))      \n",
    "    \n",
    "    studied_columnsAll_coef = pd.read_csv(os.path.join(_inputDir,'studied_columns_all_Coefficeints.csv'))\n",
    "    studied_columnsAll_Met = pd.read_csv(os.path.join(_inputDir,'studied_columns_all_Metrics.csv'))\n",
    "    studied_columnsAll_Pre = pd.read_csv(os.path.join(_inputDir,'studied_columns_all_Prediction.csv'))\n",
    "    \n",
    "    studied_columnsGen_coef = pd.read_csv(os.path.join(_inputDir,'studied_columns_generator_Coefficeints.csv'))\n",
    "    studied_columnsGen_Met = pd.read_csv(os.path.join(_inputDir,'studied_columns_generator_Metrics.csv'))\n",
    "    studied_columnsGen_Pre = pd.read_csv(os.path.join(_inputDir,'studied_columns_generator_Prediction.csv'))    \n",
    "    \n",
    "    studied_columnsCons_coef = pd.read_csv(os.path.join(_inputDir,'studied_columns_consumator_Coefficeints.csv'))\n",
    "    studied_columnsCons_Met = pd.read_csv(os.path.join(_inputDir,'studied_columns_consumator_Metrics.csv'))\n",
    "    studied_columnsCons_Pre = pd.read_csv(os.path.join(_inputDir,'studied_columns_consumator_Prediction.csv'))     \n",
    "    firstArmonic_columnsAll_coef[\"columns\"] = \"firstArmonic_columns_all\"\n",
    "    firstArmonic_columnsAll_Met[\"columns\"] = \"firstArmonic_columns_all\"\n",
    "    firstArmonic_columnsAll_Pre[\"columns\"] = \"firstArmonic_columns_all\"\n",
    "    \n",
    "    firstArmonic_columnsGen_coef[\"columns\"] = \"firstArmonic_columns_generator\"\n",
    "    firstArmonic_columnsGen_Met[\"columns\"] = \"firstArmonic_columns_generator\"\n",
    "    firstArmonic_columnsGen_Pre[\"columns\"] = \"firstArmonic_columns_generator\"    \n",
    "    \n",
    "    firstArmonic_columnsCons_coef[\"columns\"] = \"firstArmonic_columns_consumator\"\n",
    "    firstArmonic_columnsCons_Met[\"columns\"] = \"firstArmonic_columns_consumator\"\n",
    "    firstArmonic_columnsCons_Pre[\"columns\"] = \"firstArmonic_columns_consumator\"       \n",
    "    \n",
    "    studied_columnsAll_coef[\"columns\"] = \"studied_columns_all\"\n",
    "    studied_columnsAll_Met[\"columns\"] = \"studied_columns_all\"\n",
    "    studied_columnsAll_Pre[\"columns\"] = \"studied_columns_all\"        \n",
    "    \n",
    "    studied_columnsGen_coef[\"columns\"] = \"studied_columns_generator\"\n",
    "    studied_columnsGen_Met[\"columns\"] = \"studied_columns_generator\"\n",
    "    studied_columnsGen_Pre[\"columns\"] = \"studied_columns_generator\"            \n",
    "    \n",
    "    studied_columnsCons_coef[\"columns\"] = \"studied_columns_consumator\"\n",
    "    studied_columnsCons_Met[\"columns\"] = \"studied_columns_consumator\"\n",
    "    studied_columnsCons_Pre[\"columns\"] = \"studied_columns_consumator\"    \n",
    "    data_coeff = pd.concat([firstArmonic_columnsAll_coef, firstArmonic_columnsGen_coef, firstArmonic_columnsCons_coef,\n",
    "                           studied_columnsAll_coef, studied_columnsGen_coef, studied_columnsCons_coef])\n",
    "    \n",
    "    data_Metrics = pd.concat([firstArmonic_columnsAll_Met, firstArmonic_columnsGen_Met, firstArmonic_columnsCons_Met,\n",
    "                           studied_columnsAll_Met, studied_columnsGen_Met, studied_columnsCons_Met])    \n",
    "    \n",
    "    data_Prediction = pd.concat([firstArmonic_columnsAll_Pre, firstArmonic_columnsGen_Pre, firstArmonic_columnsCons_Pre,\n",
    "                          studied_columnsAll_Pre, studied_columnsGen_Pre, studied_columnsCons_Pre])    \n",
    "    data_coeff.to_csv(os.path.join(_outputDir,inputdir+'_Coefficients.csv'))\n",
    "    data_Metrics.to_csv(os.path.join(_outputDir,inputdir+'_Metrics.csv'))\n",
    "    data_Prediction.to_csv(os.path.join(_outputDir,inputdir+'_Prediction.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebcb2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeL1_CSV_v2(inputdir, outputdir):\n",
    "    isExist = os.path.exists(outputdir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outputdir)\n",
    "    _inputDir = os.path.join(os.getcwd(), inputdir)\n",
    "    _outputDir = os.path.join(os.getcwd(), outputdir)\n",
    "    firstArmonic_columnsAll_Met = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_all_Metrics.csv'))\n",
    "    firstArmonic_columnsAll_Pre = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_all_Prediction.csv'))\n",
    "    \n",
    "    firstArmonic_columnsGen_Met = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_generator_Metrics.csv'))\n",
    "    firstArmonic_columnsGen_Pre = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_generator_Prediction.csv'))    \n",
    "    \n",
    "    firstArmonic_columnsCons_Met = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_consumator_Metrics.csv'))\n",
    "    firstArmonic_columnsCons_Pre = pd.read_csv(os.path.join(_inputDir,'firstArmonic_columns_consumator_Prediction.csv'))      \n",
    "    \n",
    "    studied_columnsAll_Met = pd.read_csv(os.path.join(_inputDir,'studied_columns_all_Metrics.csv'))\n",
    "    studied_columnsAll_Pre = pd.read_csv(os.path.join(_inputDir,'studied_columns_all_Prediction.csv'))\n",
    "    \n",
    "    studied_columnsGen_Met = pd.read_csv(os.path.join(_inputDir,'studied_columns_generator_Metrics.csv'))\n",
    "    studied_columnsGen_Pre = pd.read_csv(os.path.join(_inputDir,'studied_columns_generator_Prediction.csv'))    \n",
    "    \n",
    "    studied_columnsCons_Met = pd.read_csv(os.path.join(_inputDir,'studied_columns_consumator_Metrics.csv'))\n",
    "    studied_columnsCons_Pre = pd.read_csv(os.path.join(_inputDir,'studied_columns_consumator_Prediction.csv'))     \n",
    "    firstArmonic_columnsAll_Met[\"columns\"] = \"firstArmonic_columns_all\"\n",
    "    firstArmonic_columnsAll_Pre[\"columns\"] = \"firstArmonic_columns_all\"\n",
    "    \n",
    "    firstArmonic_columnsGen_Met[\"columns\"] = \"firstArmonic_columns_generator\"\n",
    "    firstArmonic_columnsGen_Pre[\"columns\"] = \"firstArmonic_columns_generator\"    \n",
    "    \n",
    "    firstArmonic_columnsCons_Met[\"columns\"] = \"firstArmonic_columns_consumator\"\n",
    "    firstArmonic_columnsCons_Pre[\"columns\"] = \"firstArmonic_columns_consumator\"       \n",
    "    \n",
    "    studied_columnsAll_Met[\"columns\"] = \"studied_columns_all\"\n",
    "    studied_columnsAll_Pre[\"columns\"] = \"studied_columns_all\"        \n",
    "    \n",
    "    studied_columnsGen_Met[\"columns\"] = \"studied_columns_generator\"\n",
    "    studied_columnsGen_Pre[\"columns\"] = \"studied_columns_generator\"            \n",
    "    \n",
    "    studied_columnsCons_Met[\"columns\"] = \"studied_columns_consumator\"\n",
    "    studied_columnsCons_Pre[\"columns\"] = \"studied_columns_consumator\"    \n",
    "    \n",
    "    data_Metrics = pd.concat([firstArmonic_columnsAll_Met, firstArmonic_columnsGen_Met, firstArmonic_columnsCons_Met,\n",
    "                           studied_columnsAll_Met, studied_columnsGen_Met, studied_columnsCons_Met])    \n",
    "    \n",
    "    data_Prediction = pd.concat([firstArmonic_columnsAll_Pre, firstArmonic_columnsGen_Pre, firstArmonic_columnsCons_Pre,\n",
    "                          studied_columnsAll_Pre, studied_columnsGen_Pre, studied_columnsCons_Pre])    \n",
    "    data_Metrics.to_csv(os.path.join(_outputDir,inputdir+'_Metrics.csv'))\n",
    "    data_Prediction.to_csv(os.path.join(_outputDir,inputdir+'_Prediction.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "248ab2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_dir = \"11_MachineLearning_NN\"\n",
    "mergeL1_CSV_v2(\"data_normal\", _dir)\n",
    "mergeL1_CSV_v2(\"scaled_data_normal\", _dir)\n",
    "mergeL1_CSV_v2(\"1_ordin_data_normal\", _dir)\n",
    "mergeL1_CSV_v2(\"1_ordin_scaled_data_normal\", _dir)\n",
    "mergeL1_CSV_v2(\"2_ordin_data_normal\", _dir)\n",
    "mergeL1_CSV_v2(\"2_ordin_scaled_data_normal\", _dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0309527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeL2_CSV_v1(inputdir, outputdir):\n",
    "    isExist = os.path.exists(outputdir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outputdir)\n",
    "    _inputDir = os.path.join(os.getcwd(), inputdir)\n",
    "    _outputDir = os.path.join(os.getcwd(), outputdir)\n",
    "    _1_ordin_data_normal_Coefficients = pd.read_csv(os.path.join(_inputDir,'1_ordin_data_normal_Coefficients.csv'))\n",
    "    _1_ordin_data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'1_ordin_data_normal_Metrics.csv'))\n",
    "    _1_ordin_data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'1_ordin_data_normal_Prediction.csv'))\n",
    "    _1_ordin_scaled_data_normal_Coefficients = pd.read_csv(os.path.join(_inputDir,'1_ordin_scaled_data_normal_Coefficients.csv'))\n",
    "    _1_ordin_scaled_data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'1_ordin_scaled_data_normal_Metrics.csv'))\n",
    "    _1_ordin_scaled_data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'1_ordin_scaled_data_normal_Prediction.csv'))\n",
    "    _2_ordin_data_normal_Coefficients = pd.read_csv(os.path.join(_inputDir,'2_ordin_data_normal_Coefficients.csv'))\n",
    "    _2_ordin_data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'2_ordin_data_normal_Metrics.csv'))\n",
    "    _2_ordin_data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'2_ordin_data_normal_Prediction.csv'))\n",
    "    _2_ordin_scaled_data_normal_Coefficients = pd.read_csv(os.path.join(_inputDir,'2_ordin_scaled_data_normal_Coefficients.csv'))\n",
    "    _2_ordin_scaled_data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'2_ordin_scaled_data_normal_Metrics.csv'))\n",
    "    _2_ordin_scaled_data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'2_ordin_scaled_data_normal_Prediction.csv'))\n",
    "    _data_normal_Coefficients = pd.read_csv(os.path.join(_inputDir,'data_normal_Coefficients.csv'))\n",
    "    _data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'data_normal_Metrics.csv'))\n",
    "    _data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'data_normal_Prediction.csv'))\n",
    "    _scaled_data_normal_Coefficients = pd.read_csv(os.path.join(_inputDir,'scaled_data_normal_Coefficients.csv'))\n",
    "    _scaled_data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'scaled_data_normal_Metrics.csv'))\n",
    "    _scaled_data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'scaled_data_normal_Prediction.csv'))    \n",
    "    \n",
    "    _1_ordin_data_normal_Coefficients[\"data Input\"]=\"1_ordin_data_normal\"\n",
    "    _1_ordin_data_normal_Metrics[\"data Input\"]=\"1_ordin_data_normal\"\n",
    "    _1_ordin_data_normal_Prediction[\"data Input\"]=\"1_ordin_data_normal\"\n",
    "    \n",
    "    _1_ordin_scaled_data_normal_Coefficients[\"data Input\"]=\"1_ordin_scaled_data_normal\"\n",
    "    _1_ordin_scaled_data_normal_Metrics[\"data Input\"]=\"1_ordin_scaled_data_normal\"\n",
    "    _1_ordin_scaled_data_normal_Prediction[\"data Input\"]=\"1_ordin_scaled_data_normal\"\n",
    "    \n",
    "    _2_ordin_data_normal_Coefficients[\"data Input\"]=\"2_ordin_data_normal\"\n",
    "    _2_ordin_data_normal_Metrics[\"data Input\"]=\"2_ordin_data_normal\"\n",
    "    _2_ordin_data_normal_Prediction[\"data Input\"]=\"2_ordin_data_normal\"\n",
    "    \n",
    "    _2_ordin_scaled_data_normal_Coefficients[\"data Input\"]=\"2_ordin_scaled_data_normal\"\n",
    "    _2_ordin_scaled_data_normal_Metrics[\"data Input\"]=\"2_ordin_scaled_data_normal\"\n",
    "    _2_ordin_scaled_data_normal_Prediction[\"data Input\"]=\"2_ordin_scaled_data_normal\"\n",
    "    \n",
    "    _data_normal_Coefficients[\"data Input\"]=\"data_normal\"\n",
    "    _data_normal_Metrics[\"data Input\"]=\"data_normal\"\n",
    "    _data_normal_Prediction[\"data Input\"]=\"data_normal\"\n",
    "    \n",
    "    _scaled_data_normal_Coefficients[\"data Input\"]=\"scaled_data_normal\"\n",
    "    _scaled_data_normal_Metrics[\"data Input\"]=\"scaled_data_normal\"\n",
    "    _scaled_data_normal_Prediction[\"data Input\"]=\"scaled_data_normal\"\n",
    "    \n",
    "    data_coeff = pd.concat([_scaled_data_normal_Coefficients, \n",
    "                            _1_ordin_scaled_data_normal_Coefficients, \n",
    "                            _2_ordin_scaled_data_normal_Coefficients,\n",
    "                            _data_normal_Coefficients, \n",
    "                            _1_ordin_data_normal_Coefficients, \n",
    "                            _2_ordin_data_normal_Coefficients])\n",
    "    \n",
    "    data_Metrics = pd.concat([_scaled_data_normal_Metrics, \n",
    "                              _1_ordin_scaled_data_normal_Metrics, \n",
    "                              _2_ordin_scaled_data_normal_Metrics,\n",
    "                              _data_normal_Metrics, \n",
    "                              _1_ordin_data_normal_Metrics, \n",
    "                              _2_ordin_data_normal_Metrics])    \n",
    "    \n",
    "    data_Prediction = pd.concat([_scaled_data_normal_Prediction, \n",
    "                                 _1_ordin_scaled_data_normal_Prediction, \n",
    "                                 _2_ordin_scaled_data_normal_Prediction,\n",
    "                                 _data_normal_Prediction, \n",
    "                                 _1_ordin_data_normal_Prediction, \n",
    "                                 _2_ordin_data_normal_Prediction])    \n",
    "    data_coeff[\"Model\"]=inputdir\n",
    "    data_Metrics[\"Model\"]=inputdir\n",
    "    data_Prediction[\"Model\"]=inputdir\n",
    "    \n",
    "    data_coeff.to_csv(os.path.join(_outputDir,'All_Coefficients.csv'))\n",
    "    data_Metrics.to_csv(os.path.join(_outputDir,'All_Metrics.csv'))\n",
    "    data_Prediction.to_csv(os.path.join(_outputDir,'All_Prediction.csv'))    \n",
    "    \n",
    "def mergeL2_CSV_v2(inputdir, outputdir):\n",
    "    isExist = os.path.exists(outputdir)\n",
    "    if not isExist:\n",
    "        os.makedirs(outputdir)\n",
    "    _inputDir = os.path.join(os.getcwd(), inputdir)\n",
    "    _outputDir = os.path.join(os.getcwd(), outputdir)\n",
    "\n",
    "    _1_ordin_data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'1_ordin_data_normal_Metrics.csv'))\n",
    "    _1_ordin_data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'1_ordin_data_normal_Prediction.csv'))\n",
    "    \n",
    "    _1_ordin_scaled_data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'1_ordin_scaled_data_normal_Metrics.csv'))\n",
    "    _1_ordin_scaled_data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'1_ordin_scaled_data_normal_Prediction.csv'))\n",
    "    \n",
    "    _2_ordin_data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'2_ordin_data_normal_Metrics.csv'))\n",
    "    _2_ordin_data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'2_ordin_data_normal_Prediction.csv'))\n",
    "    \n",
    "    _2_ordin_scaled_data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'2_ordin_scaled_data_normal_Metrics.csv'))\n",
    "    _2_ordin_scaled_data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'2_ordin_scaled_data_normal_Prediction.csv'))\n",
    "    \n",
    "    _data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'data_normal_Metrics.csv'))\n",
    "    _data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'data_normal_Prediction.csv'))\n",
    "   \n",
    "    _scaled_data_normal_Metrics = pd.read_csv(os.path.join(_inputDir,'scaled_data_normal_Metrics.csv'))\n",
    "    _scaled_data_normal_Prediction = pd.read_csv(os.path.join(_inputDir,'scaled_data_normal_Prediction.csv'))    \n",
    "    \n",
    "    \n",
    "    _1_ordin_data_normal_Metrics[\"data Input\"]=\"1_ordin_data_normal\"\n",
    "    _1_ordin_data_normal_Prediction[\"data Input\"]=\"1_ordin_data_normal\"\n",
    "    \n",
    "    \n",
    "    _1_ordin_scaled_data_normal_Metrics[\"data Input\"]=\"1_ordin_scaled_data_normal\"\n",
    "    _1_ordin_scaled_data_normal_Prediction[\"data Input\"]=\"1_ordin_scaled_data_normal\"\n",
    "    \n",
    "    \n",
    "    _2_ordin_data_normal_Metrics[\"data Input\"]=\"2_ordin_data_normal\"\n",
    "    _2_ordin_data_normal_Prediction[\"data Input\"]=\"2_ordin_data_normal\"\n",
    "    \n",
    "    \n",
    "    _2_ordin_scaled_data_normal_Metrics[\"data Input\"]=\"2_ordin_scaled_data_normal\"\n",
    "    _2_ordin_scaled_data_normal_Prediction[\"data Input\"]=\"2_ordin_scaled_data_normal\"\n",
    "    \n",
    "    \n",
    "    _data_normal_Metrics[\"data Input\"]=\"data_normal\"\n",
    "    _data_normal_Prediction[\"data Input\"]=\"data_normal\"\n",
    "    \n",
    "    \n",
    "    _scaled_data_normal_Metrics[\"data Input\"]=\"scaled_data_normal\"\n",
    "    _scaled_data_normal_Prediction[\"data Input\"]=\"scaled_data_normal\"\n",
    "    \n",
    "    data_Metrics = pd.concat([_scaled_data_normal_Metrics, \n",
    "                              _1_ordin_scaled_data_normal_Metrics, \n",
    "                              _2_ordin_scaled_data_normal_Metrics,\n",
    "                              _data_normal_Metrics, \n",
    "                              _1_ordin_data_normal_Metrics, \n",
    "                              _2_ordin_data_normal_Metrics])    \n",
    "    \n",
    "    data_Prediction = pd.concat([_scaled_data_normal_Prediction, \n",
    "                                 _1_ordin_scaled_data_normal_Prediction, \n",
    "                                 _2_ordin_scaled_data_normal_Prediction,\n",
    "                                 _data_normal_Prediction, \n",
    "                                 _1_ordin_data_normal_Prediction, \n",
    "                                 _2_ordin_data_normal_Prediction])  \n",
    "\n",
    "    data_Metrics[\"Model\"]=inputdir\n",
    "    data_Prediction[\"Model\"]=inputdir    \n",
    "    \n",
    "    data_Metrics.to_csv(os.path.join(_outputDir,'All_Metrics.csv'))\n",
    "    data_Prediction.to_csv(os.path.join(_outputDir,'All_Prediction.csv'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a406cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergeL2_CSV_v1(\"01_LinearRegression\",\"out_01_LinearRegression\")\n",
    "mergeL2_CSV_v1(\"02_RidgeRegression\",\"out_02_RidgeRegression\")\n",
    "mergeL2_CSV_v1(\"03_RidgeRegressionCV\",\"out_03_RidgeRegressionCV\")\n",
    "mergeL2_CSV_v1(\"04_LassoRegression\",\"out_04_LassoRegression\")\n",
    "mergeL2_CSV_v1(\"05_ElasticNet\",\"out_05_ElasticNet\")\n",
    "mergeL2_CSV_v1(\"06_SGDRegressor\",\"out_06_SGDRegressor\")\n",
    "mergeL2_CSV_v2(\"07_SVR_Linear\",\"out_07_SVR_Linear\")\n",
    "mergeL2_CSV_v2(\"08_SVR_rbf\",\"out_08_SVR_rbf\")\n",
    "mergeL2_CSV_v2(\"09_PolynomialFeatures2\",\"out_09_PolynomialFeatures2\")\n",
    "mergeL2_CSV_v2(\"10_PolynomialFeatures3\",\"out_10_PolynomialFeatures3\")\n",
    "mergeL2_CSV_v2(\"11_MachineLearning_NN\",\"out_11_MachineLearning_NN\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e3f8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "_modelList = [\"01_LinearRegression\", \"02_RidgeRegression\", \"03_RidgeRegressionCV\", \"04_LassoRegression\", \"05_ElasticNet\"\n",
    "              , \"06_SGDRegressor\", \"07_SVR_Linear\", \"08_SVR_rbf\", \"09_PolynomialFeatures2\", \"10_PolynomialFeatures3\", \"11_MachineLearning_NN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26871532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b6d8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
